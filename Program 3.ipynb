{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a9be53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The Given Training Data Set\n",
      "\n",
      "['Sunny', 'Warm', 'Normal', 'Strong', 'Warm', 'Same', 'Yes']\n",
      "['Sunny', 'Warm', 'High', 'Strong', 'Warm', 'Same', 'Yes']\n",
      "['Rainy', 'Cold', 'High', 'Strong', 'Warm', 'Change', 'No']\n",
      "['Sunny', 'Warm', 'High', 'Strong', 'Cool', 'Change', 'Yes']\n",
      "\n",
      " the initial value of hypothesis:\n",
      "\n",
      " The most Specific hypothesis S0:[0,0,0,0,0,0]\n",
      "\n",
      "\n",
      " The most general hypothesis G0:[?,?,?,?,?,?]\n",
      "\n",
      "\n",
      " Candidate Elimination Algorithm Hypothesis Version Space Computation\n",
      "\n",
      "--------------------------------------------------------------\n",
      "For Training Example No:1 the hypothesis is S1 ['Sunny', 'Warm', 'Normal', 'Strong', 'Warm', 'Same']\n",
      "For Training Example No:1 the hypothesis is G1 ['?', '?', '?', '?', '?', '?']\n",
      "--------------------------------------------------------------\n",
      "For Training Example No:2 the hypothesis is S2 ['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n",
      "For Training Example No:2 the hypothesis is G2 ['?', '?', '?', '?', '?', '?']\n",
      "--------------------------------------------------------------\n",
      "For Training Example No:3 the hypothesis is S3 ['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n",
      "For Training Example No:3 the hypothesis is G3 [['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', 'Same']]\n",
      "--------------------------------------------------------------\n",
      "For Training Example No:4 the hypothesis is S4 ['Sunny', 'Warm', '?', 'Strong', '?', '?']\n",
      "For Training Example No:4 the  hypothesis is G4 [['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?']]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "a = []\n",
    "print(\"\\n The Given Training Data Set\\n\")\n",
    "with open('ws.csv','r')as csvFile:\n",
    "    reader = csv.reader(csvFile)\n",
    "    for row in reader:\n",
    "        a.append(row)\n",
    "        print(row)\n",
    "num_attributes = len(a[0])-1\n",
    "print(\"\\n the initial value of hypothesis:\")\n",
    "S = ['0']*num_attributes\n",
    "G = ['?']*num_attributes\n",
    "print(\"\\n The most Specific hypothesis S0:[0,0,0,0,0,0]\\n\")\n",
    "print(\"\\n The most general hypothesis G0:[?,?,?,?,?,?]\\n\")\n",
    "\n",
    "for j in range(0,num_attributes):\n",
    "    S[j]=a[0][j]\n",
    "    \n",
    "print(\"\\n Candidate Elimination Algorithm Hypothesis Version Space Computation\\n\")\n",
    "temp = []\n",
    "\n",
    "for i in range(0,len(a)):\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    if a[i][num_attributes] == 'Yes':\n",
    "        for j in range(0,num_attributes):\n",
    "            if a[i][j]!=S[j]:\n",
    "                S[j]='?'\n",
    "        for j in range(0,num_attributes):\n",
    "            for k in range(1,len(temp)):\n",
    "                if(temp[k][j]!='?' and temp[k][j]!=S[j]):\n",
    "                    del temp[k]\n",
    "        print(\"For Training Example No:{0} the hypothesis is S{0}\".format(i+1),S)\n",
    "        if(len(temp)==0):\n",
    "            print(\"For Training Example No:{0} the hypothesis is G{0}\".format(i+1),G)\n",
    "        else:\n",
    "            print(\"For Training Example No:{0} the  hypothesis is G{0}\".format(i+1),temp)\n",
    "    if a[i][num_attributes] == 'No':\n",
    "        for j in range(0,num_attributes):\n",
    "            if(S[j]!=a[i][j] and S[j]!='?'):\n",
    "                G[j]=S[j]\n",
    "                temp.append(G)\n",
    "                G=['?']*num_attributes\n",
    "        print(\"For Training Example No:{0} the hypothesis is S{0}\".format(i+1),S)\n",
    "        print(\"For Training Example No:{0} the hypothesis is G{0}\".format(i+1),temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80de34f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "[[2. 9.]\n",
      " [1. 5.]\n",
      " [3. 6.]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89265793]\n",
      " [0.88624911]\n",
      " [0.89055375]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n",
    "y = np.array(([92], [86], [89]), dtype=float)\n",
    "y = y/100\n",
    "#Sigmoid Function\n",
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "#Derivative of Sigmoid Function\n",
    "def derivatives_sigmoid(x):\n",
    "    return x * (1 - x)\n",
    "#Variable initialization\n",
    "epoch=10000 #Setting training iterations\n",
    "lr=0.1 #Setting learning rate\n",
    "inputlayer_neurons = 2 #number of features in data set\n",
    "hiddenlayer_neurons = 3 #number of hidden layers neurons\n",
    "output_neurons = 1 #number of neurons at output layer\n",
    "#weight and bias initialization\n",
    "wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons))\n",
    "bh=np.random.uniform(size=(1,hiddenlayer_neurons))\n",
    "wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons))\n",
    "bout=np.random.uniform(size=(1,output_neurons))\n",
    "#draws a random range of numbers uniformly of dim x*y\n",
    "for i in range(epoch):\n",
    "#Forward Propogation\n",
    "    hinp1=np.dot(X,wh)\n",
    "    hinp=hinp1 + bh\n",
    "    hlayer_act = sigmoid(hinp)\n",
    "    outinp1=np.dot(hlayer_act,wout)\n",
    "    outinp= outinp1+ bout\n",
    "    output = sigmoid(outinp)\n",
    "#Backpropagation\n",
    "    EO = y-output\n",
    "    outgrad = derivatives_sigmoid(output)\n",
    "    d_output = EO* outgrad\n",
    "    EH = d_output.dot(wout.T)\n",
    "    hiddengrad = derivatives_sigmoid(hlayer_act)#how much hidden layer wts contributed to error\n",
    "    d_hiddenlayer = EH * hiddengrad\n",
    "    wout += hlayer_act.T.dot(d_output) *lr# dotproduct of nextlayererror and currentlayerop\n",
    "    bout += np.sum(d_output, axis=0,keepdims=True) *lr\n",
    "    wh += X.T.dot(d_hiddenlayer) *lr\n",
    "    bh += np.sum(d_hiddenlayer, axis=0,keepdims=True) *lr\n",
    "print(\"Input: \\n\" + str(X)) \n",
    "print(\"Actual Output: \\n\" + str(y))\n",
    "print(\"Predicted Output: \\n\" ,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4435e1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " outlook\n",
      "    overcast\n",
      "       [b'yes']\n",
      "    rainy\n",
      "       windy\n",
      "          b'Strong'\n",
      "             [b'no']\n",
      "          b'Weak'\n",
      "             [b'yes']\n",
      "    sunny\n",
      "       humidity\n",
      "          b'high'\n",
      "             [b'no']\n",
      "          b'normal'\n",
      "             [b'yes']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, attribute):\n",
    "        self.attribute = attribute\n",
    "        self.children = []\n",
    "        self.answer = \"\"\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.attribute\n",
    "\n",
    "def read_data(filename):\n",
    "\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        datareader = csv.reader(csvfile)\n",
    "        metadata = next(datareader)\n",
    "        traindata=[]\n",
    "        for row in datareader:\n",
    "            traindata.append(row)\n",
    "    \n",
    "    return (metadata, traindata)\n",
    "\n",
    "def subtables(data, col, delete):\n",
    "    dict = {}\n",
    "    items = np.unique(data[:, col]) # get unique values in particular column\n",
    "    \n",
    "    count = np.zeros((items.shape[0], 1), dtype=np.int32)   #number of row = number of values \n",
    "    \n",
    "    for x in range(items.shape[0]):\n",
    "        for y in range(data.shape[0]):\n",
    "            if data[y, col] == items[x]:\n",
    "                count[x] += 1\n",
    "    #count has the data of number of times each value is present in\n",
    "                \n",
    "    for x in range(items.shape[0]):\n",
    "        dict[items[x]] = np.empty((int(count[x]), data.shape[1]), dtype=\"|S32\")\n",
    "         \n",
    "        pos = 0\n",
    "        for y in range(data.shape[0]):\n",
    "            if data[y, col] == items[x]:\n",
    "                dict[items[x]][pos] = data[y]\n",
    "                pos += 1     \n",
    "        \n",
    "        if delete:\n",
    "           dict[items[x]] = np.delete(dict[items[x]], col, 1)\n",
    "    return items, dict    \n",
    "        \n",
    "def entropy(S):\n",
    "    items = np.unique(S)\n",
    "    if items.size == 1:\n",
    "        return 0\n",
    "    \n",
    "    counts = np.zeros((items.shape[0], 1))\n",
    "    sums = 0\n",
    "    \n",
    "    for x in range(items.shape[0]):\n",
    "   \n",
    "        counts[x] = sum(S == items[x]) / (S.size)\n",
    "        \n",
    "\n",
    "\n",
    "    for count in counts:\n",
    "        sums += -1 * count * math.log(count, 2)\n",
    "    \n",
    "    return sums\n",
    "    \n",
    "def gain_ratio(data, col):\n",
    "    items, dict = subtables(data, col, delete=False) \n",
    "    #item is the unique value and dict is the data corresponding to it\n",
    "    total_size = data.shape[0]\n",
    "    entropies = np.zeros((items.shape[0], 1))\n",
    "      \n",
    "    for x in range(items.shape[0]):\n",
    "        ratio = dict[items[x]].shape[0]/(total_size)\n",
    "        entropies[x] = ratio * entropy(dict[items[x]][:, -1])\n",
    "        \n",
    "        \n",
    "    total_entropy = entropy(data[:, -1])\n",
    "   \n",
    "    \n",
    "    for x in range(entropies.shape[0]):\n",
    "        total_entropy -= entropies[x]\n",
    "        \n",
    "    return total_entropy\n",
    "\n",
    "def create_node(data, metadata):\n",
    "      \n",
    "     if (np.unique(data[:, -1])).shape[0] == 1:\n",
    "        node = Node(\"\")\n",
    "        node.answer = np.unique(data[:, -1])\n",
    "        return node\n",
    "     \n",
    "     gains = np.zeros((data.shape[1] - 1, 1))  \n",
    "     #size of gains= number of attribute to calculate gain\n",
    "    \n",
    "    \n",
    "     for col in range(data.shape[1] - 1):\n",
    "         gains[col] = gain_ratio(data, col)\n",
    "        \n",
    "     split = np.argmax(gains)\n",
    "  \n",
    "    \n",
    "     node = Node(metadata[split])    \n",
    "     metadata = np.delete(metadata, split, 0)\n",
    "                          \n",
    "    \n",
    "     items, dict = subtables(data, split, delete=True)\n",
    "    \n",
    "     for x in range(items.shape[0]):\n",
    "        child = create_node(dict[items[x]], metadata)\n",
    "        node.children.append((items[x], child))\n",
    "    \n",
    "     return node        \n",
    "    \n",
    "def empty(size):\n",
    "    s = \"\"\n",
    "    for x in range(size):\n",
    "        s += \"   \"\n",
    "    return s\n",
    "\n",
    "def print_tree(node, level):\n",
    "    if node.answer != \"\":\n",
    "        print(empty(level), node.answer)\n",
    "        return\n",
    "        \n",
    "    print(empty(level), node.attribute)\n",
    "    \n",
    "    for value, n in node.children:\n",
    "        print(empty(level + 1), value)\n",
    "        print_tree(n, level + 2)\n",
    "        \n",
    "\n",
    "metadata, traindata = read_data(\"tennis.csv\")\n",
    "data = np.array(traindata)\n",
    "node = create_node(data, metadata)\n",
    "print_tree(node, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca42245c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
